# AI Maturity Model - Mid-Level Software Engineer
*Focus: Owning medium complexity features and mentoring juniors*

| **Dimension** | **Level 1: Exploratory** | **Level 2: Applied** | **Level 3: Standardized** | **Level 4: Strategic** | **Level 5: Transformational** |
|---------------|---------------------------|----------------------|---------------------------|------------------------|-------------------------------|
| **AI Literacy & Competency** | Inconsistent AI usage across different development tasks. Limited understanding of AI capabilities for medium-complexity work. | Regularly uses AI for feature development and code reviews. Developing advanced prompting skills for architectural decisions. | Proficient with AI across coding, testing, and design tasks. Mentors junior developers on AI tool usage and best practices. | Recognized as team's AI advocate. Teaches effective AI evaluation methods. Helps establish AI competency standards for development work. | Expert judgment on AI application across development lifecycle. Creates learning resources for team AI adoption. |
| **Workflow & SDLC Integration** | Uses AI for individual tasks without considering feature-level impact. May not integrate AI into design and estimation processes. | Integrates AI into feature planning, coding, and testing phases. Incorporates AI considerations into effort estimation and technical decisions. | Applies AI tools across entire feature development lifecycle. Establishes AI integration patterns for medium-complexity projects. | Identifies AI opportunities across sprint planning and execution. Contributes to team workflow improvements based on AI capabilities. | Designs comprehensive AI-enabled development workflows for feature teams. Drives adoption of AI-integrated development practices. |
| **Tooling Integration** | Basic usage of AI tools without optimization for feature development workflow. Limited understanding of tool integration with design processes. | Competent with AI tools for design, implementation, and testing. Configures tools to support feature development and code review processes. | Efficiently operates AI toolchain including design assistants, code generators, and testing tools. Helps establish team tooling standards. | Evaluates and tests new AI tools for feature development. Identifies integration opportunities and workflow optimizations. | Shapes team's AI tooling strategy. Mentors others on tool selection and integration patterns for feature development. |
| **Trust, Safety & Governance** | Limited awareness of AI risks in feature development context. May not consider security implications of AI-generated code in larger systems. | Follows AI governance policies for feature development. Considers security and compliance in AI-assisted technical decisions. | Actively enforces AI governance in code reviews and technical design. Identifies AI-related risks in feature architecture and integration. | Helps implement AI governance practices for feature development. Contributes to team guidelines for AI usage in technical design. | Champions AI safety standards for feature development. Drives improvements to AI governance frameworks within team scope. |
| **AI-Augmented Collaboration** | AI usage primarily individual. Limited sharing of AI contributions in collaborative technical work. | Transparently shares AI usage in technical discussions and design reviews. Incorporates AI into collaborative problem-solving sessions. | Effectively uses AI in cross-functional collaboration. Develops team practices for AI-assisted technical decision-making. | Leads AI-enhanced technical discussions and design sessions. Mentors junior developers on collaborative AI usage. | Creates mature AI collaboration practices for feature teams. Facilitates AI-enhanced technical workshops and design sessions. |
| **Business Impact & Innovation** | Focuses on individual productivity without measuring feature-level impact. Limited consideration of AI's role in technical trade-offs. | Demonstrates productivity improvements in feature delivery. Advocates for AI adoption based on measurable results in feature development. | Shows consistent improvements in feature quality and delivery velocity. Tracks AI's impact on technical decision-making and outcomes. | Leverages AI to drive technical innovation in feature development. Experiments with AI-enabled approaches to complex technical problems. | Identifies compound value from AI across multiple features and projects. Helps team understand AI ROI for feature development. |